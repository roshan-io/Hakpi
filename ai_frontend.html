 <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="icon" type="image/png" sizes="180x180" href="favicon.png">
  <title>Dashboard</title>
  <link href="https://fonts.googleapis.com/css2?family=Audiowide&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Chakra+Petch&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Russo+One&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css" />

  <style>

   canvas#bgCanvas {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  z-index: 0;
  overflow: hidden;
}

    :root {
      --bg: #0e1117;
      --card: #161b22;
      --text: #c9d1d9;
      --accent: #58a6ff;
      --border: #30363d;
    }

    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }

    body {

      color: var(--text);
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      padding: 0;
      margin: 0;
      background: black;

    }

    .card {
      width: 70vw;
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 10px;
      padding: 1rem;
      box-shadow: 0 0 10px rgba(0,0,0,0.3);
    }
    .double-height {
      grid-column: span 2;
      grid-row: span 2;
    }

.wrapper {
  display: flex;
  justify-content: center;
  align-items: center;
  height: 100vh;
  width: 100vw;
  background: radial-gradient(circle at center, #050510 0%, #000 100%);
  overflow: hidden; /* prevents scrolling */
  position: relative;
  padding: 0;
  margin: 0;
}


.wrapper::before {
  content: "";
  position: absolute;
  width: 500px;
  height: 500px;
  background: radial-gradient(circle, rgba(120, 80, 255, 0.25), transparent 70%);
  filter: blur(120px);
  z-index: 0;
}



/* voice styling */

  .voice-card {
  display: flex;
  flex-direction: column;
  justify-content: space-between;
  text-align: center;
  background: radial-gradient(circle at top left, #0a0a0f, #0d0d16);
  box-shadow: 0 0 20px rgba(150, 100, 255, 0.2);
  border-radius: 1.2rem;
  padding: 1rem;
  color: #e0e0ff;
  position: relative;
  overflow: hidden;
}

.voice-card::before {
  content: "";
  position: absolute;
  inset: 0;
  background: linear-gradient(120deg, #a46bff22, #ff79c622);
  pointer-events: none;
  mix-blend-mode: overlay;
}

.voice-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  font-weight: 500;
  font-size: 1rem;
}

#voiceStatus {
  color: #a46bff;
  font-family: monospace;
}

.voice-display {
  flex: 1;
  background: rgba(255, 255, 255, 0.04);
  border-radius: 0.8rem;
  margin: 1rem 0;
  padding: 1rem;
  font-size: 0.95rem;
  color: #dcdcff;
  text-shadow: 0 0 4px #a46bff55;
  overflow-y: auto;
  max-height: 100px;
  transition: 0.2s;
}

.voice-controls {
  display: flex;
  justify-content: center;
  align-items: center;
}


.audio-visualizer-container {
  position: relative;
  width: 80%;
  height: 120px;
  margin: 0 auto;
  display: flex;
  justify-content: center;
  align-items: flex-end;
  background: transparent;
  gap: 30px; /* small space between visualizer and mic */
}

#visualizer {
  width: 100%;
  height: 100%;
  border-radius: 10px;
  background: transparent;
  display: block;
  position: relative;
}

/* Mic button positioned slightly above the visualizer's bottom line */
#voiceBtn {
  position: relative;
  bottom: 15px;              /* lift mic slightly above visualizer baseline */
  width: 47px;
  height: 47px;
  border-radius: 50%;
  background: linear-gradient(90deg, #a46bff, #ff79c6);
  border: none;
  color: #fff;
  font-size: 1.1rem;
  cursor: pointer;
  outline: none;
  transition: transform 0.3s ease, box-shadow 0.3s ease;
  flex-shrink: 0;            /* prevent size shrink when resizing */
  margin-bottom: 0px;
}

#voiceBtn:hover {
  transform: scale(1.08);
  box-shadow: 0 0 15px #ff79c688;
}

#voiceBtn.active {
  box-shadow: 0 0 25px 4px #a46bffaa;
  animation: pulse 1.2s infinite;
}


@keyframes pulse {
  0% { box-shadow: 0 0 8px 2px #a46bff55; }
  50% { box-shadow: 0 0 20px 5px #ff79c655; }
  100% { box-shadow: 0 0 8px 2px #a46bff55; }
}

</style>
</head>

<body>

    <canvas id="bgCanvas"></canvas>

<div class="wrapper">


    <div class="card double-height ">


    <div class="voice-header">  
    <h3>Voice Input</h3>  
    <span id="voiceStatus">Idle</span>  
  </div>  

  <div class="voice-display">  
    <p id="liveText">Press Mic to start speaking</p>  
  </div>  
      <div class="audio-visualizer-container">  
         <canvas id="visualizer"></canvas>  
        <button id="voiceBtn">  
           <span class="glow-ring"></span>  
       ðŸŽ¤
    </button> 
</div>  




    </div>  

</div>


<script>

const voiceBtn = document.getElementById("voiceBtn");
const voiceStatus = document.getElementById("voiceStatus");

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

if (!SpeechRecognition) {
  voiceStatus.textContent = "Speech recognition not supported.";
  voiceBtn.disabled = true;
} else {
  const recognition = new SpeechRecognition();
  recognition.lang = "en-US";
  recognition.interimResults = false; // no live transcription
  recognition.continuous = false;

  voiceBtn.onclick = async () => {
    try {
      await navigator.mediaDevices.getUserMedia({ audio: true });
      recognition.start();
    } catch (err) {
      voiceStatus.textContent = "Mic access denied.";
    }
  };

  recognition.onstart = () => {
    voiceStatus.textContent = "ListeningÃ¢â‚¬Â¦ Ã°Å¸Å½Â§";
    voiceBtn.classList.add("active");
  };

  recognition.onresult = (event) => {
    let finalTranscript = "";
    for (let i = event.resultIndex; i < event.results.length; i++) {
      if (event.results[i].isFinal) {
        finalTranscript += event.results[i][0].transcript;
      }
    }

    // You can handle commands here using finalTranscript
    console.log("Heard:", finalTranscript);
    // e.g., trigger page navigation or other actions
  };

  recognition.onerror = (e) => {
    voiceStatus.textContent = "Error";
    console.error("STT Error:", e.error);
    voiceBtn.classList.remove("active");
  };

  recognition.onend = () => {
    voiceStatus.textContent = "Idle";
    voiceBtn.classList.remove("active");
  };
}    

</script>

  <script>
document.addEventListener('DOMContentLoaded', () => {
  const canvas = document.getElementById('visualizer');
  const ctx = canvas.getContext('2d');
  const voiceBtn = document.getElementById('voiceBtn');
  const voiceStatus = document.getElementById('voiceStatus');

  let audioCtx, analyser, source, dataArray, barStore = [];
  let isVisualizing = false;
  let animationId;

  // --- Resize visualizer dynamically ---
  function resize() {
    const rect = canvas.parentElement.getBoundingClientRect();
    canvas.width = rect.width;
    canvas.height = rect.height;
  }
  resize();
  window.addEventListener('resize', resize);

  // --- Initialize visualizer ---
  async function startVisualizer(stream) {
    if (!audioCtx) {
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 1024;
      source = audioCtx.createMediaStreamSource(stream);
      source.connect(analyser);
      dataArray = new Uint8Array(analyser.frequencyBinCount);
    }

    isVisualizing = true;

    function draw() {
      if (!isVisualizing) return;
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      const h = canvas.height, baseY = Math.round(h / 2);

      // baseline
      ctx.save();
      ctx.strokeStyle = "#fff";
      ctx.shadowColor = "#fff";
      ctx.shadowBlur = 8;
      ctx.lineWidth = 1.3;
      ctx.beginPath();
      ctx.moveTo(0, baseY);
      ctx.lineTo(canvas.width, baseY);
      ctx.stroke();
      ctx.restore();

      analyser.getByteFrequencyData(dataArray);
      const nLines = Math.floor(canvas.width / 5.2);
      const xStep = canvas.width / nLines;
      const sampleStep = dataArray.length / nLines;
      const upMax = h * 0.33, downMax = h * 0.06;
      const SMOOTH = 0.35, SENSITIVITY = 1.65;

      for (let i = 0; i < nLines; i++) {
        const idx = Math.floor(i * sampleStep);
        let rawValue = dataArray[idx] / 255;
        rawValue = Math.pow(rawValue, 1.03) * SENSITIVITY;
        rawValue = Math.min(rawValue, 1);
        if (!barStore[i]) barStore[i] = rawValue;
        barStore[i] += (rawValue - barStore[i]) * SMOOTH;
        const value = barStore[i];

        const upLen = value * upMax;
        const downLen = value * downMax;
        const x = xStep * i + xStep / 2;

        const blendGrad = ctx.createLinearGradient(x, baseY - upLen, x, baseY + downLen);
        blendGrad.addColorStop(0.0, "#89edff");
        blendGrad.addColorStop(0.45, "#fff");
        blendGrad.addColorStop(0.53, "#fff");
        blendGrad.addColorStop(0.85, "#fd89e9");
        blendGrad.addColorStop(1.0, "#fd79d0");

        ctx.save();
        ctx.lineCap = "round";
        ctx.strokeStyle = blendGrad;
        ctx.shadowColor = "#a0eaff";
        ctx.shadowBlur = 13;
        ctx.lineWidth = 2.2;
        ctx.beginPath();
        ctx.moveTo(x, baseY + downLen);
        ctx.lineTo(x, baseY - upLen);
        ctx.stroke();
        ctx.restore();
      }
      animationId = requestAnimationFrame(draw);
    }
    draw();
  }

  function stopVisualizer() {
  isVisualizing = false;
  cancelAnimationFrame(animationId);

  // clear and redraw baseline
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  const h = canvas.height, baseY = Math.round(h / 2);
  ctx.save();
  ctx.strokeStyle = "#fff";
  ctx.shadowColor = "#fff";
  ctx.shadowBlur = 8;
  ctx.lineWidth = 1.3;
  ctx.beginPath();
  ctx.moveTo(0, baseY);
  ctx.lineTo(canvas.width, baseY);
  ctx.stroke();
  ctx.restore();
}

  // --- Speech Recognition ---
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SpeechRecognition) {
    voiceStatus.textContent = "Speech recognition not supported.";
    voiceBtn.disabled = true;
    return;
  }

  const recognition = new SpeechRecognition();
  recognition.lang = "en-US";
  recognition.interimResults = false;
  recognition.continuous = false;

  let micStream;

  voiceBtn.onclick = async () => {
    if (voiceBtn.classList.contains("active")) {
      recognition.stop();
      stopVisualizer();
      voiceBtn.classList.remove("active");
      voiceStatus.textContent = "Stopped";
      return;
    }

    try {
      micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      voiceBtn.classList.add("active");
      voiceStatus.textContent = "ListeningÃ¢â‚¬Â¦ Ã°Å¸Å½Â§";
      startVisualizer(micStream);
      recognition.start();
    } catch (err) {
      voiceStatus.textContent = "Mic access denied.";
      console.error(err);
    }
  };

  recognition.onresult = (event) => {
    let finalTranscript = "";
    for (let i = event.resultIndex; i < event.results.length; i++) {
      if (event.results[i].isFinal) {
        finalTranscript += event.results[i][0].transcript;
      }
    }
    console.log("Heard:", finalTranscript);
    voiceStatus.textContent = "Heard: " + finalTranscript;
  };

  recognition.onerror = (e) => {
    console.error("STT Error:", e.error);
    voiceStatus.textContent = "Error";
    voiceBtn.classList.remove("active");
    stopVisualizer();
  };

  recognition.onend = () => {
    voiceStatus.textContent = "Idle";
    voiceBtn.classList.remove("active");
    stopVisualizer();
  };
});
</script>

</body>
</head>